{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# UNIFR API EPUCK : Object Detection Methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model with custom images "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook will guide you through the different steps if you want to train the YOLO model on your own dataset, to then use the weights with the e-puck2 and the UNIFR_API_EPUCK.\n",
    "\n",
    "Note that the model implemented in the API was scrapped to the maximum, to be as light as possible and run on low-end laptops. So all the training methods and associated possibilities have been removed. Therefore, we will have to use the official released version and copy the weight file. \n",
    "\n",
    "The blog: https://blog.paperspace.com/train-yolov5-custom-data/ is a good documentation if necessary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob, os\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Set up the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start by cloning the YOLOv5 repository:\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">git clone https://github.com/ultralytics/yolov5\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "Then I'd suggest creating a new environment with conda or virtualenv, depending on what you use.\n",
    "\n",
    "Once done, install the requirements\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">pip install -r yolov5/requirements.txt\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "While you're at it, directly install the API as well\n",
    "\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">pip install unifr_api_epuck\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "Finally, move this notebook inside the /yolov5 directory\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Create the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a folder to store the pictures you'll take with the robot\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!mkdir custom_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then a proposition for a pictures capturing controller. An image will be taken every so often. The LED turning on indicates that the robot is about to take a picture. \n",
    "\n",
    "Note:\n",
    "\n",
    "- The bigger the dataset, the better\n",
    "\n",
    "- Try to cover all the possible situation (background, lighting, number of object in the field of view, etc...)\n",
    "\n",
    "- Try to balance the classes, about the same number of each class should appear"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from unifr_api_epuck import wrapper\n",
    "\n",
    "#Adapt the IP to your robot\n",
    "MY_IP = \"192.168.1.12\"\n",
    "robot = wrapper.get_robot(MY_IP)\n",
    "\n",
    "robot.init_camera(\"custom_dataset\")\n",
    "\n",
    "# Get the last image number to not overwrite\n",
    "n = 0\n",
    "while os.path.exists(\"custom_dataset/image_{:05}.bmp\".format(n)):\n",
    "    n += 1\n",
    "\n",
    "\n",
    "picture = 0\n",
    "counter = 0\n",
    "\n",
    "#Takes only 50 images, useful to change robot, situation. lighting, etc. \n",
    "while robot.go_on() and picture < 10:\n",
    "\n",
    "    if counter%100 == 0:\n",
    "\n",
    "        robot.enable_led(4)\n",
    "\n",
    "    elif counter%100 == 10:\n",
    "\n",
    "        robot.take_picture(\"image_{:05}\".format(n))\n",
    "        robot.disable_led(4)\n",
    "        picture += 1\n",
    "        n += 1\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "robot.clean_up()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Label the images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you have to label all the images, for each images, a corresponding .txt file must be created. \n",
    "\n",
    "- For Mac and Windows: HyperLabel is apparently recommended\n",
    "\n",
    "- For Linux, I used labelimg\n",
    "\n",
    "The choice is ultimetaly up to you"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Organize and prepare for training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once your \"custom_dataset/\" folders looks like:\n",
    "\n",
    "- image_00001.bmp\n",
    "- image_00001.txt\n",
    "- image_00002.bmp\n",
    "- image_00002.txt\n",
    "- ...\n",
    "\n",
    "You can run the following cell to organize your data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# put your own path here\n",
    "dataset_path = 'custom_dataset'\n",
    "\n",
    "# Percentage of images to be used for the validation set\n",
    "percentage_test = 20\n",
    "!mkdir training\n",
    "!mkdir training/data\n",
    "!mkdir training/data/images\n",
    "!mkdir training/data/labels\n",
    "!mkdir training/data/images/train\n",
    "!mkdir training/data/images/valid\n",
    "!mkdir training/data/labels/train\n",
    "!mkdir training/data/labels/valid\n",
    "# Populate the folders\n",
    "p = percentage_test/100\n",
    "for pathAndFilename in glob.iglob(os.path.join(dataset_path, \"*.bmp\")):  \n",
    "    title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n",
    "    if random.random() <=p :\n",
    "        os.system(f\"cp {dataset_path}/{title}.bmp training/data/images/valid\")\n",
    "        os.system(f\"cp {dataset_path}/{title}.txt training/data/labels/valid\")\n",
    "    else:\n",
    "        os.system(f\"cp {dataset_path}/{title}.bmp training/data/images/train\")\n",
    "        os.system(f\"cp {dataset_path}/{title}.txt training/data/labels/train\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then in the training directory, you need to move the correct model.yaml"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.system(f\"cp models/yolov5m.yaml training\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WARNING\n",
    "\n",
    "At the top of this file, change the variable nc to your number of class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then create a second file, \"dataset.yaml\", with information about the paths, the number and the name of classes:\n",
    "\n",
    "```\n",
    "\n",
    "# train and val datasets (image directory or *.txt file with image paths)\n",
    "train: training/data/images/train/\n",
    "val: training/data/images/valid/\n",
    "# number of classes\n",
    "nc: 6\n",
    "# class names\n",
    "names: ['Red Block','Black Block','Black Ball','Blue Block','E-puck','Green Block']\n",
    "\n",
    "```\n",
    "\n",
    "## WARNING\n",
    "\n",
    "This second \"dataset.yaml\" file must also be in the directory \"/training\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once your training folder contains:\n",
    " - data\n",
    " - dataset.yaml\n",
    " - yolov5m.yaml\n",
    "\n",
    "With both .yaml files modified in regard to your classes, you can continue."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simply run the following cell:\n",
    "\n",
    "Adapt the batch size to your GPU (with a RTX 3080, I was able to use 128, it depending on your setup)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python train.py --img 160 --batch 64 --epochs 300 --data training/dataset.yaml --cfg training/yolov5m.yaml --weights yolov5m.pt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6: Recover the weight file\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Once the training is finish, you can go in \"/runs/training/exp_current\"\n",
    "\n",
    "Here you can see different plot and informations about the training.\n",
    "\n",
    "In the \"/weights\" folder, you'll find the file: \"best.pt\"\n",
    "\n",
    "This is the file you have to copy, and can later on use when calling the function:\n",
    "\n",
    "robot.initiate_model(\"best.pt\")"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('yolo': conda)"
  },
  "interpreter": {
   "hash": "d751a9d0ff6ce6c7c1d01eb180d86c5e6638704ade7d1d9b283f21a54b2268cf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}